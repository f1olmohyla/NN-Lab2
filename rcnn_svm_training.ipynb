{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R-CNN SVM Training\n",
    "\n",
    "Train linear SVMs with hard negative mining for aircraft detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Apple Silicon GPU acceleration enabled\n",
      "\n",
      "âœ“ Setup complete\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd() / \"rcnn\"))\n",
    "\n",
    "from rcnn.config.config import RCNNConfig\n",
    "from rcnn.train_svm import SVMTrainer\n",
    "from rcnn.data import AirbusRCNNDataset\n",
    "\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "    print(\"Apple Silicon GPU acceleration enabled\")\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "    print(\"Note: Training will be slow on CPU\")\n",
    "\n",
    "print(\"\\nâœ“ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Training Configuration:\n",
      "  Fine-tuned model: artifacts/rcnn/finetuned_cnn_best.pth\n",
      "  Feature layer: fc7 (4096-dim)\n",
      "\n",
      "SVM criteria (stricter than fine-tuning):\n",
      "  Positive IoU: 1.0 (GT boxes only)\n",
      "  Negative IoU: < 0.3\n",
      "  Hard negative mining: True\n",
      "\n",
      "Dataset:\n",
      "  Annotations: dataset/airbus-aircrafts-sample-dataset/annotations.csv\n",
      "  Images: dataset/airbus-aircrafts-sample-dataset/images\n",
      "\n",
      "âœ“ Configuration loaded\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "BASE_DIR = Path(\"dataset/airbus-aircrafts-sample-dataset\")\n",
    "ANNOTATIONS_CSV = BASE_DIR / \"annotations.csv\"\n",
    "IMAGES_DIR = BASE_DIR / \"images\"\n",
    "ARTIFACTS_DIR = Path(\"artifacts/rcnn\")\n",
    "\n",
    "assert ANNOTATIONS_CSV.exists(), f\"Annotations not found: {ANNOTATIONS_CSV}\"\n",
    "assert IMAGES_DIR.exists(), f\"Images directory not found: {IMAGES_DIR}\"\n",
    "\n",
    "config = RCNNConfig()\n",
    "\n",
    "print(\"SVM Training Configuration:\")\n",
    "print(f\"  Fine-tuned model: {ARTIFACTS_DIR / 'finetuned_cnn_best.pth'}\")\n",
    "print(f\"  Feature layer: {config.feature_layer} (4096-dim)\")\n",
    "print(f\"\\nSVM criteria (stricter than fine-tuning):\")\n",
    "print(f\"  Positive IoU: {config.svm_pos_iou_threshold} (GT boxes only)\")\n",
    "print(f\"  Negative IoU: < {config.svm_neg_iou_threshold}\")\n",
    "print(f\"  Hard negative mining: {config.svm_hard_neg_mining}\")\n",
    "print(f\"\\nDataset:\")\n",
    "print(f\"  Annotations: {ANNOTATIONS_CSV}\")\n",
    "print(f\"  Images: {IMAGES_DIR}\")\n",
    "\n",
    "print(\"\\nâœ“ Configuration loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize SVM Trainer\n",
    "\n",
    "**This cell defines:** `trainer` (needed by later cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fine-tuned CNN...\n",
      "âœ“ Loaded fine-tuned model from artifacts/rcnn/finetuned_cnn_best.pth\n",
      "\n",
      "âœ“ SVM Trainer initialized\n",
      "  Fine-tuned CNN loaded: True\n"
     ]
    }
   ],
   "source": [
    "trainer = SVMTrainer(config, device=DEVICE)\n",
    "\n",
    "print(\"\\nâœ“ SVM Trainer initialized\")\n",
    "print(f\"  Fine-tuned CNN loaded: {(ARTIFACTS_DIR / 'finetuned_cnn_best.pth').exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train SVM\n",
    "\n",
    "**This cell defines:** `svm` (the trained SVM classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_full = pd.read_csv(ANNOTATIONS_CSV)\n",
    "annotations_subset = annotations_full[annotations_full['image_id'].isin(\n",
    "    annotations_full['image_id'].unique()[:20]\n",
    ")]\n",
    "subset_csv = BASE_DIR.parent / \"temp_annotations.csv\"\n",
    "annotations_subset.to_csv(subset_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "R-CNN Stage 3: SVM Training\n",
      "============================================================\n",
      "\n",
      "Creating SVM training dataset...\n",
      "Note: Using stricter IoU thresholds than fine-tuning\n",
      "  Positives: IoU â‰ˆ 1.0 (ground-truth boxes only)\n",
      "  Negatives: IoU < 0.3\n",
      "Building proposal index for stage: svm\n",
      "Total images to process: 20\n",
      "\n",
      "[1/20] Processing: 4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg (generating proposals...) done\n",
      "[2/20] Processing: 74d335db-bf64-424a-88d7-5c24625c50b1.jpg (generating proposals...) done\n",
      "[3/20] Processing: 4e8c95f3-bbb6-4e2f-920d-8d3b2bd1d29f.jpg (generating proposals...) done\n",
      "[4/20] Processing: 72fa2a77-cf8e-44a2-9ab2-f11ca63b4b72.jpg (generating proposals...) done\n",
      "[5/20] Processing: 2314c1b5-ec8f-4212-b42f-43365a13fd20.jpg (generating proposals...) done\n",
      "[6/20] Processing: 0641acc3-c0b9-4f9d-b0ba-7ad18aa08864.jpg (generating proposals...) done\n",
      "[7/20] Processing: bed88cf9-7887-4bfd-a1d7-b5499ee24f03.jpg (generating proposals...) done\n",
      "[8/20] Processing: 3463b88d-1e11-4c04-9868-e8c72d510556.jpg (generating proposals...) done\n",
      "[9/20] Processing: 1e7e0450-6eb3-479e-88c2-990abc8207fa.jpg (generating proposals...) done\n",
      "[10/20] Processing: 22457f2e-a740-4719-9512-056749695281.jpg (generating proposals...) done\n",
      "  â†’ Progress: 10/20 images | Positives: 0 | Negatives: 9786\n",
      "\n",
      "[11/20] Processing: 12210ad7-83f8-4b54-bb4b-e93f8ff6ac1f.jpg (generating proposals...) done\n",
      "[12/20] Processing: e5416a97-a8ea-415f-928a-e75a5090cd46.jpg (generating proposals...) done\n",
      "[13/20] Processing: f82d64a6-3bfa-4612-bcbd-847a7d89c296.jpg (generating proposals...) done\n",
      "[14/20] Processing: a32efaae-a263-4570-903f-76cf9942742f.jpg (generating proposals...) done\n",
      "[15/20] Processing: 6627e7c7-2fdd-4f3c-965e-b4d73d0a4cc2.jpg (generating proposals...) done\n",
      "[16/20] Processing: eeb978ec-5945-4def-819a-4ea903b17c2d.jpg (generating proposals...) done\n",
      "[17/20] Processing: ad36e699-4a1f-4891-b579-6e9ac3e54235.jpg (generating proposals...) done\n",
      "[18/20] Processing: b6e9f8fc-3fbd-411a-a1e5-b853e8fbe2ac.jpg (generating proposals...) done\n",
      "[19/20] Processing: a40b7aed-8db8-449d-b0e4-3debfa04281a.jpg (generating proposals...) done\n",
      "[20/20] Processing: 57af3c0a-b5ae-4e4f-a7f9-6856be2f80e5.jpg (generating proposals...) done\n",
      "  â†’ Progress: 20/20 images | Positives: 1 | Negatives: 19513\n",
      "\n",
      "Total samples - positives: 1, negatives: 19513\n",
      "\n",
      "Extracting features from 19514 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danylolitvinchuk/python-workspace/NN-Lab2/myenv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8761852b79da4522a99bcf617d7cfa52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Extracted features: (19514, 4096)\n",
      "\n",
      "SVM training data for class 1:\n",
      "  Positives (IoU â‰ˆ 1.0): 1\n",
      "  Negatives (IoU < 0.3): 19513\n",
      "  Ignored (0.3 â‰¤ IoU < 1.0): 0\n",
      "\n",
      "Training SVM for class 1...\n",
      "  Using subset of negatives: 10/19513\n",
      "  Initial training: 1 pos + 10 neg\n",
      "  Hard negative mining...\n",
      "  Found 41 hard negatives\n",
      "  Retraining with 52 samples...\n",
      "  âœ“ Training accuracy: 1.0000\n",
      "\n",
      "âœ“ Saved SVM to artifacts/rcnn/svm_class_1.pkl\n",
      "âœ“ Saved all SVMs to artifacts/rcnn/svms_all.pkl\n",
      "\n",
      "============================================================\n",
      "SVM Training Complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "    annotations_csv=subset_csv,\n",
    "    images_dir=IMAGES_DIR,\n",
    "    batch_size=128,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "âœ“ SVM training complete!\n",
      "âœ“ SVM ready for evaluation\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# trainer.train(\n",
    "#     annotations_csv=ANNOTATIONS_CSV,\n",
    "#     images_dir=IMAGES_DIR,\n",
    "#     batch_size=64,\n",
    "#     num_workers=4\n",
    "# )\n",
    "\n",
    "svm = trainer.svms[1]  # Aircraft SVM (class_id=1)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"âœ“ SVM training complete!\")\n",
    "print(f\"âœ“ SVM ready for evaluation\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Trained SVM (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded SVM from artifacts/rcnn/svm_class_1.pkl\n",
      "Skipping reload (using freshly trained SVM from above)\n"
     ]
    }
   ],
   "source": [
    "svm_path = ARTIFACTS_DIR / \"svm_class_1.pkl\"\n",
    "if svm_path.exists():\n",
    "    with open(svm_path, 'rb') as f:\n",
    "        svm = pickle.load(f)\n",
    "    print(f\"âœ“ Loaded SVM from {svm_path}\")\n",
    "else:\n",
    "    print(f\"âš ï¸  SVM not found at {svm_path}\")\n",
    "\n",
    "print(\"Skipping reload (using freshly trained SVM from above)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract Features for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for visualization and comparison...\n",
      "(This uses a smaller dataset for speed)\n",
      "\n",
      "Building proposal index for stage: svm\n",
      "Total images to process: 20\n",
      "\n",
      "[1/20] Processing: 4f833867-273e-4d73-8bc3-cb2d9ceb54ef.jpg (generating proposals...) done\n",
      "[2/20] Processing: 74d335db-bf64-424a-88d7-5c24625c50b1.jpg (generating proposals...) done\n",
      "[3/20] Processing: 4e8c95f3-bbb6-4e2f-920d-8d3b2bd1d29f.jpg (generating proposals...) done\n",
      "[4/20] Processing: 72fa2a77-cf8e-44a2-9ab2-f11ca63b4b72.jpg (generating proposals...) done\n",
      "[5/20] Processing: 2314c1b5-ec8f-4212-b42f-43365a13fd20.jpg (generating proposals...) done\n",
      "[6/20] Processing: 0641acc3-c0b9-4f9d-b0ba-7ad18aa08864.jpg (generating proposals...) done\n",
      "[7/20] Processing: bed88cf9-7887-4bfd-a1d7-b5499ee24f03.jpg (generating proposals...) done\n",
      "[8/20] Processing: 3463b88d-1e11-4c04-9868-e8c72d510556.jpg (generating proposals...) done\n",
      "[9/20] Processing: 1e7e0450-6eb3-479e-88c2-990abc8207fa.jpg (generating proposals...) done\n",
      "[10/20] Processing: 22457f2e-a740-4719-9512-056749695281.jpg (generating proposals...) done\n",
      "  â†’ Progress: 10/20 images | Positives: 0 | Negatives: 4896\n",
      "\n",
      "[11/20] Processing: 12210ad7-83f8-4b54-bb4b-e93f8ff6ac1f.jpg (generating proposals...) done\n",
      "[12/20] Processing: e5416a97-a8ea-415f-928a-e75a5090cd46.jpg (generating proposals...) done\n",
      "[13/20] Processing: f82d64a6-3bfa-4612-bcbd-847a7d89c296.jpg (generating proposals...) done\n",
      "[14/20] Processing: a32efaae-a263-4570-903f-76cf9942742f.jpg (generating proposals...) done\n",
      "[15/20] Processing: 6627e7c7-2fdd-4f3c-965e-b4d73d0a4cc2.jpg (generating proposals...) done\n",
      "[16/20] Processing: eeb978ec-5945-4def-819a-4ea903b17c2d.jpg (generating proposals...) done\n",
      "[17/20] Processing: ad36e699-4a1f-4891-b579-6e9ac3e54235.jpg (generating proposals...) done\n",
      "[18/20] Processing: b6e9f8fc-3fbd-411a-a1e5-b853e8fbe2ac.jpg (generating proposals...) done\n",
      "[19/20] Processing: a40b7aed-8db8-449d-b0e4-3debfa04281a.jpg (generating proposals...) done\n",
      "[20/20] Processing: 57af3c0a-b5ae-4e4f-a7f9-6856be2f80e5.jpg (generating proposals...) done\n",
      "  â†’ Progress: 20/20 images | Positives: 0 | Negatives: 9756\n",
      "\n",
      "Total samples - positives: 0, negatives: 9756\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      5\u001b[39m vis_dataset = AirbusRCNNDataset(\n\u001b[32m      6\u001b[39m     annotations_csv=subset_csv,\n\u001b[32m      7\u001b[39m     images_dir=IMAGES_DIR,\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     cache_proposals=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Extract features using the trainer's CNN\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m vis_features, vis_labels, vis_ious = \u001b[43mtrainer\u001b[49m.extract_features(\n\u001b[32m     15\u001b[39m     vis_dataset,\n\u001b[32m     16\u001b[39m     batch_size=\u001b[32m64\u001b[39m,\n\u001b[32m     17\u001b[39m     num_workers=\u001b[32m4\u001b[39m\n\u001b[32m     18\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Create masks for SVM training samples\u001b[39;00m\n\u001b[32m     21\u001b[39m pos_mask = (vis_labels == \u001b[32m1\u001b[39m) & (vis_ious >= \u001b[32m0.99\u001b[39m)  \u001b[38;5;66;03m# Positives: IoU â‰ˆ 1.0\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Extracting features for visualization and comparison...\")\n",
    "print(\"(This uses a smaller dataset for speed)\\n\")\n",
    "\n",
    "vis_dataset = AirbusRCNNDataset(\n",
    "    annotations_csv=subset_csv,\n",
    "    images_dir=IMAGES_DIR,\n",
    "    stage=\"svm\",\n",
    "    num_proposals=500,\n",
    "    cache_proposals=True,\n",
    ")\n",
    "\n",
    "vis_features, vis_labels, vis_ious = trainer.extract_features(\n",
    "    vis_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "pos_mask = (vis_labels == 1) & (vis_ious >= 0.99)\n",
    "neg_mask = vis_ious < 0.3\n",
    "\n",
    "print(\"\\nFeature extraction complete:\")\n",
    "print(f\"  Total samples: {len(vis_features)}\")\n",
    "print(f\"  Positives (IoU â‰ˆ 1.0): {pos_mask.sum()}\")\n",
    "print(f\"  Negatives (IoU < 0.3): {neg_mask.sum()}\")\n",
    "print(f\"  Ignored (0.3 â‰¤ IoU < 1.0): {len(vis_features) - pos_mask.sum() - neg_mask.sum()}\")\n",
    "\n",
    "print(\"\\nâœ“ Features ready for visualization and comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Feature Space (PCA Projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_features = np.vstack([\n",
    "    vis_features[pos_mask][:200],\n",
    "    vis_features[neg_mask][:200]\n",
    "])\n",
    "sample_labels = np.concatenate([\n",
    "    np.ones(min(200, pos_mask.sum())),\n",
    "    np.zeros(min(200, neg_mask.sum()))\n",
    "])\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "features_2d = pca.fit_transform(sample_features)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "colors = ['red', 'green']\n",
    "labels_text = ['Background', 'Aircraft']\n",
    "\n",
    "for label in [0, 1]:\n",
    "    mask = sample_labels == label\n",
    "    ax.scatter(\n",
    "        features_2d[mask, 0],\n",
    "        features_2d[mask, 1],\n",
    "        c=colors[label],\n",
    "        label=labels_text[label],\n",
    "        alpha=0.6,\n",
    "        s=50\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "ax.set_title('SVM Training Samples (PCA 2D Projection)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ARTIFACTS_DIR / 'svm_feature_space.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ“ Saved to: {ARTIFACTS_DIR / 'svm_feature_space.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compare SVM vs CNN Softmax Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rcnn.models.cnn import AlexNetFeatureExtractor\n",
    "\n",
    "print(\"Loading fine-tuned CNN for comparison...\")\n",
    "\n",
    "cnn_classifier = AlexNetFeatureExtractor(\n",
    "    pretrained=True,\n",
    "    feature_layer=config.feature_layer,\n",
    "    num_classes=config.num_classes\n",
    ")\n",
    "\n",
    "checkpoint = torch.load(\n",
    "    ARTIFACTS_DIR / 'finetuned_cnn_best.pth',\n",
    "    map_location=DEVICE,\n",
    "    weights_only=False\n",
    ")\n",
    "cnn_classifier.load_state_dict(checkpoint['model_state_dict'])\n",
    "cnn_classifier = cnn_classifier.to(DEVICE)\n",
    "cnn_classifier.eval()\n",
    "\n",
    "print(\"âœ“ CNN classifier loaded\")\n",
    "print(\"\\nComputing predictions...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    svm_predictions = svm.predict(vis_features)\n",
    "    svm_scores = svm.decision_function(vis_features)\n",
    "    \n",
    "    vis_features_torch = torch.from_numpy(vis_features).float().to(DEVICE)\n",
    "    cnn_logits = cnn_classifier.classifier(vis_features_torch)\n",
    "    cnn_predictions = cnn_logits.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "svm_mask = pos_mask | neg_mask\n",
    "svm_labels = vis_labels[svm_mask]\n",
    "svm_preds = svm_predictions[svm_mask]\n",
    "cnn_preds = cnn_predictions[svm_mask]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION COMPARISON (on SVM validation set)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nðŸ“Š SVM Classifier:\")\n",
    "print(classification_report(\n",
    "    svm_labels, svm_preds,\n",
    "    target_names=['Background', 'Aircraft'],\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "print(\"\\nðŸ“Š CNN Softmax Classifier:\")\n",
    "print(classification_report(\n",
    "    svm_labels, cnn_preds,\n",
    "    target_names=['Background', 'Aircraft'],\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "svm_acc = (svm_preds == svm_labels).mean()\n",
    "cnn_acc = (cnn_preds == svm_labels).mean()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"SVM Accuracy:     {svm_acc:.4f}\")\n",
    "print(f\"CNN Accuracy:     {cnn_acc:.4f}\")\n",
    "print(f\"Improvement:      {(svm_acc - cnn_acc)*100:+.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrices Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "svm_cm = confusion_matrix(svm_labels, svm_preds)\n",
    "sns.heatmap(\n",
    "    svm_cm, annot=True, fmt='d', cmap='Blues',\n",
    "    xticklabels=['Background', 'Aircraft'],\n",
    "    yticklabels=['Background', 'Aircraft'],\n",
    "    ax=axes[0],\n",
    "    cbar_kws={'label': 'Count'}\n",
    ")\n",
    "axes[0].set_title('SVM Confusion Matrix')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "\n",
    "# CNN confusion matrix\n",
    "cnn_cm = confusion_matrix(svm_labels, cnn_preds)\n",
    "sns.heatmap(\n",
    "    cnn_cm, annot=True, fmt='d', cmap='Greens',\n",
    "    xticklabels=['Background', 'Aircraft'],\n",
    "    yticklabels=['Background', 'Aircraft'],\n",
    "    ax=axes[1],\n",
    "    cbar_kws={'label': 'Count'}\n",
    ")\n",
    "axes[1].set_title('CNN Softmax Confusion Matrix')\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ARTIFACTS_DIR / 'svm_vs_cnn_confusion.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ“ Saved to: {ARTIFACTS_DIR / 'svm_vs_cnn_confusion.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SVM TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "annotations = pd.read_csv(ANNOTATIONS_CSV)\n",
    "\n",
    "print(f\"\\nðŸ“ Dataset:\")\n",
    "print(f\"  Total images: {annotations['image_id'].nunique()}\")\n",
    "print(f\"  Total annotations: {len(annotations)}\")\n",
    "\n",
    "print(f\"\\nðŸ”§ SVM Configuration:\")\n",
    "print(f\"  Feature extractor: Fine-tuned AlexNet (fc7, 4096-dim)\")\n",
    "print(f\"  Positive samples: IoU = 1.0 (GT boxes only)\")\n",
    "print(f\"  Negative samples: IoU < {config.svm_neg_iou_threshold}\")\n",
    "print(f\"  Hard negative mining: {config.svm_hard_neg_mining}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Results:\")\n",
    "print(f\"  SVM accuracy:     {svm_acc:.4f} ({svm_acc*100:.2f}%)\")\n",
    "print(f\"  CNN accuracy:     {cnn_acc:.4f} ({cnn_acc*100:.2f}%)\")\n",
    "print(f\"  Improvement:      {(svm_acc - cnn_acc)*100:+.2f}%\")\n",
    "\n",
    "print(f\"\\nðŸ’¾ Saved Artifacts:\")\n",
    "artifacts = [\n",
    "    'svm_class_1.pkl',\n",
    "    'svms_all.pkl',\n",
    "    'svm_feature_space.png',\n",
    "    'svm_vs_cnn_confusion.png'\n",
    "]\n",
    "for artifact in artifacts:\n",
    "    path = ARTIFACTS_DIR / artifact\n",
    "    if path.exists():\n",
    "        size_mb = path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  âœ“ {artifact} ({size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"  âœ— {artifact} (not found)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… STAGE 3 COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nðŸ“‹ Next Steps:\")\n",
    "print(\"  1. Train bounding box regressor (Stage 4)\")\n",
    "print(\"  2. Implement inference pipeline\")\n",
    "print(\"  3. Evaluate mAP on test set\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
